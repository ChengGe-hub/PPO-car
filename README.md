# PPO-car

###给出了PPO训练无人车轨迹的代码，代码运行结果展示：
## 4个动作
![Figure_2](https://github.com/ChengGe-hub/PPO-car/assets/122962934/a814aab7-abcb-4b4c-8d75-68d942c77764)
![Figure_1](https://github.com/ChengGe-hub/PPO-car/assets/122962934/5339ba93-9366-42ee-8866-18cc13ebd56e)

## 6个动作
![Figure_2](https://github.com/ChengGe-hub/PPO-car/assets/122962934/8c86ae17-2b92-4549-b871-f269a3d379a1)
![Figure_1](https://github.com/ChengGe-hub/PPO-car/assets/122962934/93230f7a-d257-4fe2-8a62-6f8fe4411387)

